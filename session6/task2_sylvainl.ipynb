{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitc5fba3495b774b3e93b3cae291c2ea6f",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Sylvain Lapeyrade (sylla801)\n",
    "# File: TSKS11-Lab6 task2_sylvainl.ipynb\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data:\n",
    "# RMSE, training data = 0.886\n",
    "# RMSE, test data = 0.898\n",
    "train_file1 = './validate_code_netflix/validate_code.training'\n",
    "test_file1 = './validate_code_netflix/validate_code.test'\n",
    "movie_file1 = './validate_code_netflix/validate_code.moviename'\n",
    "\n",
    "# personal files => sylvainl\n",
    "# RMSE, training data = 0.8835\n",
    "# RMSE, test data = 0.8992\n",
    "train_file2 = './sylvainl/training/sylvainl.training'\n",
    "test_file2 = './sylvainl/test/sylvainl.test'\n",
    "movie_file2 = './sylvainl/moviename/sylvainl.moviename'\n",
    "\n",
    "# Task 2:\n",
    "# RMSE, training data = ???\n",
    "# RMSE, test data = ???\n",
    "train_file = './sylvainl/training/task---2.training'\n",
    "test_file = './sylvainl/test/task---2.test'\n",
    "movie_file = './sylvainl/moviename/task---2.moviename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train edge list:\nUser, Movie, Rating\n[[   4    1    4]\n [   7    1    3]\n [  12    1    4]\n ...\n [1885 1500    3]\n [1934 1500    4]\n [1989 1500    4]]\n\nTrain size: 183183\nTraining users: 2000\nTraining movies: 1500\n\nTraining Matrix:\n [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [4. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "# *** TRAINING ***\n",
    "train_edge_list = np.loadtxt(train_file, delimiter=',', dtype=int)\n",
    "train_users, train_movies, train_ratings = (\n",
    "    train_edge_list[:, 0], train_edge_list[:, 1], train_edge_list[:, 2])\n",
    "\n",
    "print(\"Train edge list:\")\n",
    "print(\"User, Movie, Rating\")\n",
    "print(train_edge_list)\n",
    "\n",
    "train_size = len(train_edge_list)\n",
    "nr_train_users = max(train_users)\n",
    "nr_train_movies = max(train_movies)\n",
    "\n",
    "print(\"\\nTrain size: {}\".format(train_size))\n",
    "print(\"Training users: {}\".format(nr_train_users))\n",
    "print(\"Training movies: {}\".format(nr_train_movies))\n",
    "\n",
    "# Training matrix (A)\n",
    "train_matrix = np.zeros(shape=(nr_train_users, nr_train_movies))\n",
    "for user, movie, rating in zip(train_users, train_movies, train_ratings):\n",
    "    train_matrix[int(user)-1, int(movie)-1] = int(rating)  # -1\n",
    "\n",
    "print(\"\\nTraining Matrix:\\n {}\".format(train_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train Indices\nUser, Movie\n [[   3    0]\n [   6    0]\n [  11    0]\n ...\n [1884 1499]\n [1933 1499]\n [1988 1499]]\n"
    }
   ],
   "source": [
    "# TRAINING indices: Indices where an user rated a movie\n",
    "train_indices = np.transpose(np.nonzero(train_matrix))\n",
    "# Sort by movies then by users while keeping the stability\n",
    "train_indices = train_indices[train_indices[:, 0].argsort()]\n",
    "train_indices = train_indices[train_indices[:, 1].argsort(kind='mergesort')]\n",
    "\n",
    "print(\"Train Indices\")\n",
    "print(\"User, Movie\\n\", train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test edge list:\nUser, Movie, Rating\n[[   1    1    5]\n [  28    1    4]\n [  66    1    4]\n ...\n [ 921 1500    3]\n [1058 1500    4]\n [1580 1500    4]]\n\nTest size: 20354\nTesting users: 2000\nTesting movies: 1500\n\nTesting Matrix:\n [[5. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "# *** TESTING ***\n",
    "test_edge_list = np.loadtxt(test_file, delimiter=',', dtype=int)\n",
    "test_users, test_movies, test_ratings = (\n",
    "    test_edge_list[:, 0], test_edge_list[:, 1], test_edge_list[:, 2])\n",
    "\n",
    "print(\"Test edge list:\")\n",
    "print(\"User, Movie, Rating\")\n",
    "print(test_edge_list)\n",
    "\n",
    "test_size = len(test_edge_list)\n",
    "nr_test_users = max(test_users)\n",
    "nr_test_movies = max(test_movies)\n",
    "\n",
    "print(\"\\nTest size: {}\".format(test_size))\n",
    "print(\"Testing users: {}\".format(nr_test_users))\n",
    "print(\"Testing movies: {}\".format(nr_test_movies))\n",
    "\n",
    "# Test matrix (A)\n",
    "test_matrix = np.zeros(shape=(nr_test_users, nr_test_movies))\n",
    "for u, m, r in zip(test_users, test_movies, test_ratings):\n",
    "    test_matrix[int(u) - 1, int(m) - 1] = int(r)  # -1\n",
    "\n",
    "print(\"\\nTesting Matrix:\\n {}\".format(test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test Indices\nUser, Movie\n [[   0    0]\n [  27    0]\n [  65    0]\n ...\n [ 920 1499]\n [1057 1499]\n [1579 1499]]\n"
    }
   ],
   "source": [
    "# TESTING indices: Indices where an user rated a movie\n",
    "test_indices = np.transpose(np.nonzero(test_matrix))\n",
    "\n",
    "# Sort by movies then by users while keeping the stability\n",
    "test_indices = test_indices[test_indices[:, 0].argsort()]\n",
    "test_indices = test_indices[test_indices[:, 1].argsort(kind='mergesort')]\n",
    "\n",
    "print(\"Test Indices\")\n",
    "print(\"User, Movie\\n\", test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Average Rating Training: 3.5720508999197524\n"
    }
   ],
   "source": [
    "# *** BASELINE PREDICTOR *** rum= ̄r+bU,u+bM,m\n",
    "# where bU,u and bM,m minimize the root mean-square error (RMSE)\n",
    "\n",
    "# ̄r: average rating over all users and movies\n",
    "average_rating = np.sum(train_matrix) / train_size\n",
    "print(\"Average Rating Training:\", average_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Bias user: [ 0.64223481 -0.47555967  0.49094123 ...  0.59461577 -0.25900742\n  0.51128243]\n\nBias movie: [ 0.57385074 -0.41861175 -0.53431505 ...  0.04184871  0.6463399\n  0.16070772]\n"
    }
   ],
   "source": [
    "# TASK 0: *** SIMPLE BASELINE PREDICTOR ***\n",
    "\n",
    "# bU,u: bias of user u compared to the average ̄r\n",
    "bias_user = np.zeros(shape=nr_train_users)\n",
    "for user in range(nr_train_users):\n",
    "    bias_user[user] = (np.sum(train_matrix[user]) / np.count_nonzero(train_matrix[user])) - average_rating\n",
    "print(\"Bias user:\", bias_user)\n",
    "\n",
    "# bM,m: bias of movie m compared to the average ̄r\n",
    "bias_movie = np.zeros(shape=nr_train_movies)\n",
    "for movie in range(nr_train_movies):\n",
    "    bias_movie[movie] = (np.sum(train_matrix[:, movie]) / np.count_nonzero(train_matrix[:, movie])) - average_rating\n",
    "print(\"\\nBias movie:\", bias_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Simple baseline solution\nPredicted Training Ratings:\n [4.2032625  4.31459148 3.66750633 ... 3.9237135  4.06514458 3.41843968]\nActual Training Ratings:\n [4 3 4 ... 3 4 4]\n\nGradient Error Training: [-0.2032625  -1.31459148  0.33249367 ... -0.9237135  -0.06514458\n  0.58156032]\nAverage Gradient Error Training:\n 0.0019502172812095047\nRoot Squared Mean Error Training: 0.9220415429071303\n"
    }
   ],
   "source": [
    "# TRAINING rum: predicted rating for user u of movie m\n",
    "predicted_ratings_training = np.zeros(shape=train_size)\n",
    "\n",
    "i = 0\n",
    "for user, movie in train_indices:\n",
    "    predicted_ratings_training[i] = average_rating + bias_user[user] + bias_movie[movie]\n",
    "    i+=1 \n",
    "\n",
    "# Truncate predicted ratings by setting predictions that falls below 1 to 1\n",
    "#  and any prediction that exceeds 5 to 5\n",
    "predicted_ratings_training[predicted_ratings_training < 1] = 1\n",
    "predicted_ratings_training[predicted_ratings_training > 5] = 5\n",
    "\n",
    "print(\"Simple baseline solution\")\n",
    "print(\"Predicted Training Ratings:\\n\", predicted_ratings_training)\n",
    "print(\"Actual Training Ratings:\\n\", train_ratings)\n",
    "\n",
    "# TRAINING Root Mean Squared Error \n",
    "gradient_error_training = train_ratings - predicted_ratings_training\n",
    "print(\"\\nGradient Error Training:\", gradient_error_training)\n",
    "avg_gradient_error_training = np.mean(train_ratings - predicted_ratings_training)\n",
    "print(\"Average Gradient Error Training:\\n\", avg_gradient_error_training)\n",
    "rmse_training = math.sqrt(sum((train_ratings - predicted_ratings_training)**2) / train_size)\n",
    "print(\"Root Squared Mean Error Training:\", rmse_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Simple baseline solution\nPredicted Testing Ratings:\n [4.78813645 3.28218407 5.         ... 3.60138569 3.50616227 4.10515217]\nActual Testing Ratings:\n [5 4 4 ... 3 4 4]\n\nGradient Error Testing: [ 0.21186355  0.71781593 -1.         ... -0.60138569  0.49383773\n -0.10515217]\nAverage Gradient Error Testing:\n 0.003039158661004881\nRoot Squared Mean Error Testing: 0.934499976267962\n"
    }
   ],
   "source": [
    "# TESTING rum: predicted rating for user u of movie m\n",
    "i = 0\n",
    "predicted_ratings_testing = np.zeros(shape=test_size)\n",
    "for user, movie in test_indices:\n",
    "    predicted_ratings_testing[i] = average_rating + bias_user[user] + bias_movie[movie]\n",
    "    i+=1\n",
    "\n",
    "# Truncate predicted ratings by setting predictions that falls below 1 to 1\n",
    "#  and any prediction that exceeds 5 to 5\n",
    "predicted_ratings_testing[predicted_ratings_testing < 1] = 1\n",
    "predicted_ratings_testing[predicted_ratings_testing > 5] = 5\n",
    "\n",
    "print(\"Simple baseline solution\")\n",
    "print(\"Predicted Testing Ratings:\\n\", predicted_ratings_testing)\n",
    "print(\"Actual Testing Ratings:\\n\", test_ratings)\n",
    "\n",
    "# TESTING Root Mean Squared Error\n",
    "gradient_error_testing = test_ratings - predicted_ratings_testing\n",
    "print(\"\\nGradient Error Testing:\", gradient_error_testing)\n",
    "avg_gradient_error_testing = np.mean(test_ratings - predicted_ratings_testing)\n",
    "print(\"Average Gradient Error Testing:\\n\", avg_gradient_error_testing)\n",
    "rmse_testing = math.sqrt(sum((test_ratings - predicted_ratings_testing)**2) / test_size)\n",
    "print(\"Root Squared Mean Error Testing:\", rmse_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Matrix A:\n [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 1.]]\n\nVector y:\n [ 0.4279491 -0.5720509  0.4279491 ... -0.5720509  0.4279491  0.4279491]\n\nLeast squared solutions (bias):\n [ 0.2733828  -0.7259397   0.29693682 ...  0.13029496  0.81813896\n  0.28751214]\n"
    }
   ],
   "source": [
    "# TASK 1: ***LEAST SQUARE SOLUTION***\n",
    "\n",
    "matrix_A = np.zeros((train_size, nr_train_users + nr_train_movies))\n",
    "vector_y = np.zeros(train_size)\n",
    "\n",
    "for row, i in zip(train_indices, range(train_size)):\n",
    "    matrix_A[i, int(row[0])] = 1\n",
    "    matrix_A[i, int(row[1]) + nr_train_users] = 1\n",
    "    vector_y[i] = train_matrix[row[0], row[1]] - average_rating\n",
    "\n",
    "print(\"Matrix A:\\n\", matrix_A)\n",
    "print(\"\\nVector y:\\n\", vector_y)\n",
    "\n",
    "# Bias\n",
    "bias_lstsq, _, _, _ = np.linalg.lstsq(matrix_A, vector_y, rcond=1e-3)\n",
    "print(\"\\nLeast squared solutions (bias):\\n\", bias_lstsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Least Squared Solution\nPredicted Training Ratings:\n [4.30348489 3.85870244 3.787168   ... 4.20698457 4.27459659 3.24544658]\nActual Training Ratings:\n [4 3 4 ... 3 4 4]\n\nGradient Error Training: [-0.30348489 -0.85870244  0.212832   ... -1.20698457 -0.27459659\n  0.75455342]\nAverage Gradient Error Training:\n 0.0004871461785553018\nRoot Squared Mean Error Training: 0.8957232336188603\n"
    }
   ],
   "source": [
    "# TRAINING rum: predicted rating for user u of movie m\n",
    "predicted_ratings_training = np.zeros(shape=train_size)\n",
    "train_ratings_predicted = np.zeros(shape=(nr_train_users, nr_train_movies))\n",
    "for user, movie, i in zip(train_indices[:, 0], train_indices[:, 1], range(train_size)):\n",
    "    predicted_ratings_training[i] = train_ratings_predicted[user, movie] = average_rating + bias_lstsq[user] + bias_lstsq[movie + nr_train_users]\n",
    "\n",
    "# Truncate predicted ratings by setting predictions that falls below 1 to 1\n",
    "#  and any prediction that exceeds 5 to 5\n",
    "predicted_ratings_training[predicted_ratings_training < 1] = 1\n",
    "predicted_ratings_training[predicted_ratings_training > 5] = 5\n",
    "\n",
    "print(\"Least Squared Solution\")\n",
    "print(\"Predicted Training Ratings:\\n\", predicted_ratings_training)\n",
    "print(\"Actual Training Ratings:\\n\", train_ratings)\n",
    "\n",
    "# TRAINING Root Mean Squared Error \n",
    "gradient_error_training = train_ratings - predicted_ratings_training\n",
    "print(\"\\nGradient Error Training:\", gradient_error_training)\n",
    "avg_gradient_error_training = np.mean(train_ratings - predicted_ratings_training)\n",
    "print(\"Average Gradient Error Training:\\n\", avg_gradient_error_training)\n",
    "rmse_training = math.sqrt(sum((train_ratings - predicted_ratings_training)**2) / train_size)\n",
    "print(\"Root Squared Mean Error Training:\", rmse_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Least Squared Solution\nPredicted Testing Ratings:\n [4.5143465  3.54752802 5.         ... 3.56867373 3.37054391 4.07890416]\nActual Testing Ratings:\n [5 4 4 ... 3 4 4]\n\nGradient Error Testing: [ 0.4856535   0.45247198 -1.         ... -0.56867373  0.62945609\n -0.07890416]\nAverage Gradient Error Testing:\n 0.0018268726759106677\nRoot Squared Mean Error Testing: 0.9101572909183229\n"
    }
   ],
   "source": [
    "# TESTING rum: predicted rating for user u of movie m\n",
    "predicted_ratings_testing = np.zeros(shape=test_size)\n",
    "for user, movie, i in zip(test_indices[:, 0], test_indices[:, 1], range(test_size)):\n",
    "    predicted_ratings_testing[i] = average_rating + bias_lstsq[user] + bias_lstsq[movie + nr_train_users]\n",
    "\n",
    "# Truncate predicted ratings by setting predictions that falls below 1 to 1\n",
    "#  and any prediction that exceeds 5 to 5\n",
    "predicted_ratings_testing[predicted_ratings_testing < 1] = 1\n",
    "predicted_ratings_testing[predicted_ratings_testing > 5] = 5\n",
    "\n",
    "print(\"Least Squared Solution\")\n",
    "print(\"Predicted Testing Ratings:\\n\", predicted_ratings_testing)\n",
    "print(\"Actual Testing Ratings:\\n\", test_ratings)\n",
    "\n",
    "# TESTING Root Mean Squared Error\n",
    "gradient_error_testing = test_ratings - predicted_ratings_testing\n",
    "print(\"\\nGradient Error Testing:\", gradient_error_testing)\n",
    "avg_gradient_error_testing = np.mean(test_ratings - predicted_ratings_testing)\n",
    "print(\"Average Gradient Error Testing:\\n\", avg_gradient_error_testing)\n",
    "rmse_testing = math.sqrt(sum((test_ratings - predicted_ratings_testing)**2) / test_size)\n",
    "print(\"Root Squared Mean Error Testing:\", rmse_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}